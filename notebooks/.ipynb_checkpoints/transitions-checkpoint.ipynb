{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "from scipy import interpolate\n",
    "from pydub import AudioSegment\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "from essentia.standard import *\n",
    "import essentia.streaming as ess\n",
    "import essentia.standard as es\n",
    "\n",
    "path1 = '/users/seanmullins333/desktop/Training Data/Calvin Harris/One Kiss.wav'\n",
    "path2 = '/users/seanmullins333/desktop/Training Data/Calvin Harris/Heatstroke.wav'\n",
    "y, sr = librosa.load(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transitions():\n",
    "    \n",
    "    \n",
    "\n",
    "def crossfade_highpass(path1, path2):\n",
    "    \n",
    "    marker1, marker2 = get_markers(path1, path2)\n",
    "    y1, sr1, y2, sr2 = get_y(path1, path2)\n",
    "    #EDITING THE FIRST SONG --> speeds it up and fades it out\n",
    "    start_time2 = marker2[marker2.loop_cues.notna()].loop_cues.values.tolist()[-4]\n",
    "    end_time2 = marker2[marker2.loop_cues.notna()].loop_cues.values.tolist()[-2]\n",
    "    fade_dur2 = 20\n",
    "    bpm2 = marker2.bpm[0]\n",
    "    bpm1 = marker1.bpm[0]\n",
    "\n",
    "    audio2 = speed_control(y2, sr2, start_time2, end_time2, bpm2, bpm1)\n",
    "    audio2 = highpass_control(audio2,sr2, start_time2, end_time2, 250,5)\n",
    "    audio2 = fade_out(audio2,end_time2, fade_dur2)\n",
    "\n",
    "    #EDITING THE SECOND SONG\n",
    "    fade_dur1 = 10\n",
    "\n",
    "    audio1 = fade_in(y1,0.00,fade_dur1)\n",
    "\n",
    "    df3 = markers(audio2)\n",
    "    segment2 = df3[df3.loop_cues >= start_time2].loop_cues.values.tolist()[1]\n",
    "\n",
    "    part_2_beg = list(audio2[:int(22050 * segment2)])\n",
    "    part_2_end = list(audio2[int(22050 * segment2):])\n",
    "\n",
    "    part_2_end_len = len(part_2_end)\n",
    "\n",
    "\n",
    "    part_1_beg = list(audio1[:int(part_2_end_len)])\n",
    "    part_1_end = list(audio1[int(part_2_end_len):])\n",
    "\n",
    "    overlay = np.array(part_2_end) + np.array(part_1_beg)\n",
    "    full_audio = list(part_2_beg) + list(overlay) + list(part_1_end)\n",
    "    \n",
    "    return full_audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
